import boto3
import json
import inquirer
from InquirerPy import prompt
from sagemaker.huggingface.model import HuggingFacePredictor
from src.config import ModelDeployment
from src.console import console
from src.sagemaker import SagemakerTask
from src.huggingface import HuggingFaceTask
from src.utils.model_utils import get_model_and_task, is_sagemaker_model, get_text_generation_hyperpameters
from src.utils.rich_utils import print_error
from src.schemas.deployment import Deployment
from src.schemas.model import Model
from src.schemas.query import Query
from src.session import get_sagemaker_session
from typing import Dict, Tuple, Optional


def make_query_request(endpoint_name: str, query: Query, config: Tuple[Deployment, Model]):
    if is_sagemaker_model(endpoint_name, config):
        return query_sagemaker_endpoint(endpoint_name, query, config)
    else:
        return query_hugging_face_endpoint(endpoint_name, query, config)


def parse_response(query_response):
    model_predictions = json.loads(query_response['Body'].read())
    probabilities, labels, predicted_label = model_predictions[
        'probabilities'], model_predictions['labels'], model_predictions['predicted_label']
    return probabilities, labels, predicted_label


def query_hugging_face_endpoint(endpoint_name: str, user_query: Query, config: Tuple[Deployment, Model]):
    task = get_model_and_task(endpoint_name, config)['task']
    predictor = HuggingFacePredictor(endpoint_name=endpoint_name,
                                     sagemaker_session=get_sagemaker_session())

    query = user_query.query
    context = user_query.context

    input = {"inputs": query}
    if task is not None and task == HuggingFaceTask.QuestionAnswering:
        if context is None:
            questions = [{
                "type": "input", "message": "What context would you like to provide?:", "name": "context"}]
            answers = prompt(questions)
            context = answers.get('context', '')

        if not context:
            raise Exception("Must provide context for question-answering")

        input = {}
        input['context'] = answers['context']
        input['question'] = query

    if task is not None and task == HuggingFaceTask.TextGeneration:
        parameters = get_text_generation_hyperpameters(config, user_query)
        input['parameters'] = parameters

    if task is not None and task == HuggingFaceTask.ZeroShotClassification:
        if context is None:
            questions = [
                inquirer.Text('labels',
                              message="What labels would you like to use? (comma separated values)?",
                              )
            ]
            answers = inquirer.prompt(questions)
            context = answers.get('labels', '')

        if not context:
            raise Exception(
                "Must provide labels for zero shot text classification")

        labels = context.split(',')
        input = json.dumps({
            "sequences": query,
            "candidate_labels": labels
        })

    try:
        result = predictor.predict(input)
    except Exception:
        console.print_exception()
        quit()

    print(result)
    return result


def query_sagemaker_endpoint(endpoint_name: str, user_query: Query, config: Tuple[Deployment, Model]):
    client = boto3.client('runtime.sagemaker')
    task = get_model_and_task(endpoint_name, config)['task']

    if task not in [
        SagemakerTask.ExtractiveQuestionAnswering,
        SagemakerTask.TextClassification,
        SagemakerTask.SentenceSimilarity,
        SagemakerTask.SentencePairClassification,
        SagemakerTask.Summarization,
        SagemakerTask.NamedEntityRecognition,
        SagemakerTask.TextEmbedding,
        SagemakerTask.TcEmbedding,
        SagemakerTask.TextGeneration,
        SagemakerTask.TextGeneration1,
        SagemakerTask.TextGeneration2,
        SagemakerTask.Translation,
        SagemakerTask.FillMask,
        SagemakerTask.ZeroShotTextClassification
    ]:
        print_error("""
Querying this model type inside of Model Manager isnâ€™t yet supported. 
You can query it directly through the API endpoint - see here for documentation on how to do this:
https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_runtime_InvokeEndpoint.html
                    """)
        raise Exception("Unsupported")

    # MIME content type varies per deployment
    content_type = "application/x-text"
    accept_type = "application/json;verbose"

    # Depending on the task, input needs to be formatted differently.
    # e.g. question-answering needs to have {question: , context: }
    query = user_query.query
    context = user_query.context
    input = query.encode("utf-8")
    match task:
        case SagemakerTask.ExtractiveQuestionAnswering:
            if context is None:
                questions = [
                    {
                        'type': 'input',
                        'name': 'context',
                        'message': "What context would you like to provide?",
                    }
                ]
                answers = prompt(questions)
                context = answers.get("context", '')

            if not context:
                raise Exception("Must provide context for question-answering")

            content_type = "application/list-text"
            input = json.dumps([query, context]).encode("utf-8")

        case SagemakerTask.SentencePairClassification:
            if context is None:
                questions = [
                    inquirer.Text('context',
                                  message="What sentence would you like to compare against?",
                                  )
                ]
                answers = inquirer.prompt(questions)
                context = answers.get("context", '')
            if not context:
                raise Exception(
                    "Must provide a second sentence for sentence pair classification")

            content_type = "application/list-text"
            input = json.dumps([query, context]).encode("utf-8")
        case SagemakerTask.ZeroShotTextClassification:
            if context is None:
                questions = [
                    inquirer.Text('labels',
                                  message="What labels would you like to use? (comma separated values)?",
                                  )
                ]
                answers = inquirer.prompt(questions)
                context = answers.get('labels', '')

            if not context:
                raise Exception(
                    "must provide labels for zero shot text classification")
            labels = context.split(',')

            content_type = "application/json"
            input = json.dumps({
                "sequences": query,
                "candidate_labels": labels,
            }).encode("utf-8")
        case SagemakerTask.TextGeneration:
            parameters = get_text_generation_hyperpameters(config, user_query)
            input = json.dumps({
                "inputs": query,
                "parameters": parameters,
            }).encode("utf-8")
            content_type = "application/json"

    try:
        response = client.invoke_endpoint(
            EndpointName=endpoint_name, ContentType=content_type, Body=input, Accept=accept_type)
    except Exception:
        console.print_exception()
        quit()

    model_predictions = json.loads(response['Body'].read())
    print(model_predictions)
    return model_predictions


def test(endpoint_name: str):
    text1 = 'astonishing ... ( frames ) profound ethical and philosophical questions in the form of dazzling pop entertainment'
    text2 = 'simply stupid , irrelevant and deeply , truly , bottomlessly cynical '

    for text in [text1, text2]:
        query_sagemaker_endpoint(endpoint_name, text.encode('utf-8'))
